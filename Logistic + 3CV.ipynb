{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3b27f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "import random\n",
    "breast_cancer = load_breast_cancer(as_frame=True)\n",
    "DF = breast_cancer.frame\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b2c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = DF[['target']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5856dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "X = DF.iloc[: , :N].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e55f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "scaler=MinMaxScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "Y=scaler.fit_transform(Y)\n",
    "X=X.T\n",
    "Y=Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c63ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_f(z):\n",
    "    return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9497e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_f(w,b,X):\n",
    "# get the total number\n",
    "    m = X.shape[1]\n",
    "# create a zero vector \n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    A = sigmoid_f(np.dot(w.T,X)+b)\n",
    "# given the hypothesis that\n",
    "# if y_hat >=0.5, y=1; otherwise y=0\n",
    "    for i in range(m):\n",
    "        if A[0,i]>=0.5: \n",
    "            Y_prediction[0,i] = 1\n",
    "        else:\n",
    "            Y_prediction[0,i] = 0\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300f385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss_f(w,b,X,Y): # get the total number \n",
    "    m = X.shape[1]\n",
    "    # calculate the predicted y and the cost\n",
    "    A = sigmoid_f(np.dot(w.T,X)+b)\n",
    "    cost = -(np.sum(Y*np.log(A)+(1-Y)*np.log(1-A)))/m\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80b7da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_f(w, b, X, Y):\n",
    "    m = X.shape[1]\n",
    "# calculate the y_hat\n",
    "    A = sigmoid_f(np.dot(w.T,X)+b)\n",
    "    dZ = A-Y\n",
    "# derivative of loss w.r.t weight\n",
    "    dw = (np.dot(X,dZ.T))/m\n",
    "# derivative of loss w.r.t intercept \n",
    "    db = (np.sum(dZ))/m\n",
    "            # return the dw and db inside the grads\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9dd7854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_f(w, b, X, Y, epochs, learning_rate):\n",
    "    costs = []\n",
    "    for i in range(epochs):\n",
    "                # applying gradients descent function\n",
    "        grads = gradient_f(w,b,X,Y) \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "                # updating the weights and intercept\n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "                # calculating the cost function\n",
    "        cost = binary_loss_f(w,b,X,Y)\n",
    "                # save the cost every 100 iterations and print it out\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    Y_pred = classifier_f(w,b,X)\n",
    "    accuracy = 1 - np.mean(np.abs(Y_pred - Y))\n",
    "    print(\"Accuracy on set:\",accuracy )\n",
    "    result = {\"costs\" : cost,\n",
    "              \"Weights\": w,\n",
    "              \"b\":b, \n",
    "              \"accuracy\":accuracy, \n",
    "              \"Y_pred\" : Y_pred\n",
    "              } \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "267fec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.691598\n",
      "Cost after iteration 100: 0.575444\n",
      "Cost after iteration 200: 0.498529\n",
      "Cost after iteration 300: 0.444337\n",
      "Cost after iteration 400: 0.404313\n",
      "Cost after iteration 500: 0.373555\n",
      "Cost after iteration 600: 0.349145\n",
      "Cost after iteration 700: 0.329262\n",
      "Cost after iteration 800: 0.312716\n",
      "Cost after iteration 900: 0.298702\n",
      "Cost after iteration 1000: 0.286655\n",
      "Cost after iteration 1100: 0.276167\n",
      "Cost after iteration 1200: 0.266937\n",
      "Cost after iteration 1300: 0.258738\n",
      "Cost after iteration 1400: 0.251393\n",
      "Cost after iteration 1500: 0.244768\n",
      "Cost after iteration 1600: 0.238751\n",
      "Cost after iteration 1700: 0.233257\n",
      "Cost after iteration 1800: 0.228214\n",
      "Cost after iteration 1900: 0.223563\n",
      "Cost after iteration 2000: 0.219256\n",
      "Cost after iteration 2100: 0.215252\n",
      "Cost after iteration 2200: 0.211517\n",
      "Cost after iteration 2300: 0.208021\n",
      "Cost after iteration 2400: 0.204741\n",
      "Cost after iteration 2500: 0.201653\n",
      "Cost after iteration 2600: 0.198741\n",
      "Cost after iteration 2700: 0.195986\n",
      "Cost after iteration 2800: 0.193376\n",
      "Cost after iteration 2900: 0.190897\n",
      "Cost after iteration 3000: 0.188540\n",
      "Cost after iteration 3100: 0.186293\n",
      "Cost after iteration 3200: 0.184148\n",
      "Cost after iteration 3300: 0.182098\n",
      "Cost after iteration 3400: 0.180135\n",
      "Cost after iteration 3500: 0.178254\n",
      "Cost after iteration 3600: 0.176448\n",
      "Cost after iteration 3700: 0.174713\n",
      "Cost after iteration 3800: 0.173044\n",
      "Cost after iteration 3900: 0.171436\n",
      "Cost after iteration 4000: 0.169886\n",
      "Cost after iteration 4100: 0.168390\n",
      "Cost after iteration 4200: 0.166946\n",
      "Cost after iteration 4300: 0.165550\n",
      "Cost after iteration 4400: 0.164199\n",
      "Cost after iteration 4500: 0.162891\n",
      "Cost after iteration 4600: 0.161624\n",
      "Cost after iteration 4700: 0.160395\n",
      "Cost after iteration 4800: 0.159203\n",
      "Cost after iteration 4900: 0.158045\n",
      "Cost after iteration 5000: 0.156921\n",
      "Cost after iteration 5100: 0.155828\n",
      "Cost after iteration 5200: 0.154764\n",
      "Cost after iteration 5300: 0.153730\n",
      "Cost after iteration 5400: 0.152722\n",
      "Cost after iteration 5500: 0.151741\n",
      "Cost after iteration 5600: 0.150785\n",
      "Cost after iteration 5700: 0.149852\n",
      "Cost after iteration 5800: 0.148942\n",
      "Cost after iteration 5900: 0.148054\n",
      "Cost after iteration 6000: 0.147187\n",
      "Cost after iteration 6100: 0.146341\n",
      "Cost after iteration 6200: 0.145513\n",
      "Cost after iteration 6300: 0.144705\n",
      "Cost after iteration 6400: 0.143914\n",
      "Cost after iteration 6500: 0.143141\n",
      "Cost after iteration 6600: 0.142384\n",
      "Cost after iteration 6700: 0.141643\n",
      "Cost after iteration 6800: 0.140918\n",
      "Cost after iteration 6900: 0.140207\n",
      "Cost after iteration 7000: 0.139512\n",
      "Cost after iteration 7100: 0.138829\n",
      "Cost after iteration 7200: 0.138161\n",
      "Cost after iteration 7300: 0.137505\n",
      "Cost after iteration 7400: 0.136863\n",
      "Cost after iteration 7500: 0.136232\n",
      "Cost after iteration 7600: 0.135613\n",
      "Cost after iteration 7700: 0.135005\n",
      "Cost after iteration 7800: 0.134409\n",
      "Cost after iteration 7900: 0.133824\n",
      "Cost after iteration 8000: 0.133248\n",
      "Cost after iteration 8100: 0.132683\n",
      "Cost after iteration 8200: 0.132128\n",
      "Cost after iteration 8300: 0.131583\n",
      "Cost after iteration 8400: 0.131046\n",
      "Cost after iteration 8500: 0.130519\n",
      "Cost after iteration 8600: 0.130000\n",
      "Cost after iteration 8700: 0.129490\n",
      "Cost after iteration 8800: 0.128989\n",
      "Cost after iteration 8900: 0.128495\n",
      "Cost after iteration 9000: 0.128009\n",
      "Cost after iteration 9100: 0.127531\n",
      "Cost after iteration 9200: 0.127060\n",
      "Cost after iteration 9300: 0.126597\n",
      "Cost after iteration 9400: 0.126140\n",
      "Cost after iteration 9500: 0.125691\n",
      "Cost after iteration 9600: 0.125248\n",
      "Cost after iteration 9700: 0.124812\n",
      "Cost after iteration 9800: 0.124383\n",
      "Cost after iteration 9900: 0.123959\n",
      "Accuracy on set: 0.968365553602812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'costs': 0.12354588987961958,\n",
       " 'Weights': array([[-1.1434992 ],\n",
       "        [-1.30912899],\n",
       "        [-1.24649986],\n",
       "        [-1.57207726],\n",
       "        [ 0.4750165 ],\n",
       "        [-0.71928016],\n",
       "        [-2.48155437],\n",
       "        [-3.34113606],\n",
       "        [ 0.41115119],\n",
       "        [ 2.03552652],\n",
       "        [-1.64607791],\n",
       "        [ 0.46426397],\n",
       "        [-1.29014345],\n",
       "        [-1.22181241],\n",
       "        [ 0.5989249 ],\n",
       "        [ 0.91627859],\n",
       "        [ 0.51280409],\n",
       "        [ 0.27778245],\n",
       "        [ 0.7602846 ],\n",
       "        [ 0.93372269],\n",
       "        [-2.3582086 ],\n",
       "        [-2.14580201],\n",
       "        [-2.21834932],\n",
       "        [-2.15158438],\n",
       "        [-0.98440036],\n",
       "        [-1.12134051],\n",
       "        [-1.78357458],\n",
       "        [-3.27399809],\n",
       "        [-1.05564681],\n",
       "        [-0.1960431 ]]),\n",
       " 'b': 7.596854589203279,\n",
       " 'accuracy': 0.968365553602812,\n",
       " 'Y_pred': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "         0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "         1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "         1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "         0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "         1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "         1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "         1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "         1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "         1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 1.]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = X.shape[0]\n",
    "w = np.zeros((dim,1))\n",
    "b=0\n",
    "result = optimizer_f(w, b, X, Y, 10000, 0.05)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "107b2db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final function is: 7.596855 + -1.143499*mean radius + -1.309129*mean texture + -1.246500*mean perimeter + -1.572077*mean area + 0.475017*mean smoothness + -0.719280*mean compactness + -2.481554*mean concavity + -3.341136*mean concave points + 0.411151*mean symmetry + 2.035527*mean fractal dimension + -1.646078*radius error + 0.464264*texture error + -1.290143*perimeter error + -1.221812*area error + 0.598925*smoothness error + 0.916279*compactness error + 0.512804*concavity error + 0.277782*concave points error + 0.760285*symmetry error + 0.933723*fractal dimension error + -2.358209*worst radius + -2.145802*worst texture + -2.218349*worst perimeter + -2.151584*worst area + -0.984400*worst smoothness + -1.121341*worst compactness + -1.783575*worst concavity + -3.273998*worst concave points + -0.196043*worst fractal dimension. \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "w = result['Weights']\n",
    "b = result['b']\n",
    "names = DF.columns.values.tolist()\n",
    "print(\"The final function is: %f +\"%(b),end=\"\")\n",
    "for i in range(len(w)-2):\n",
    "    print(\" %f*%s +\"%(w[i],names[i]), end=\"\")\n",
    "print(\" %f*%s. \"%(w[len(w)-1],names[len(w)-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bf7e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n: negative related\n",
    "#p: postive related\n",
    "#Cn: coefficient n\n",
    "#Rank from positive to negative (biggest to smallest)\n",
    "#C10. p 2.03552652  mean fractal dimension\n",
    "#C20. p 0.93372269  fractal dimension error\n",
    "#C16. p 0.91627859  compactness error\n",
    "#C19. p 0.7602846   symmetry error\n",
    "#C15. p 0.5989249   smoothness error\n",
    "#C17. p 0.51280409  concavity error\n",
    "#C5. p 0.4750165    mean smoothness\n",
    "#C12. p 0.46426397  texture error\n",
    "#C9. p 0.41115119   mean symmetry\n",
    "#C18. p 0.27778245  concave points error\n",
    "#C30. n -0.1960431  worst fractal dimension\n",
    "#C6. n -0.71928016  mean compactness\n",
    "#C25. n -0.98440036  worst smoothness\n",
    "#C29. n -1.05564681  worst symmetry\n",
    "#C26. n -1.12134051  worst compactness\n",
    "#C1. n -1.1434992    mean radius\n",
    "#C14. n -1.22181241  area error\n",
    "#C3. n -1.24649986   mean perimeter\n",
    "#C13. n -1.29014345  perimeter error\n",
    "#C2. n -1.30912899   mean texture\n",
    "#C4. n -1.57207726   mean area\n",
    "#C11. n -1.64607791  radius error\n",
    "#C27. n -1.78357458  worst concavity\n",
    "#C22. n -2.14580201  worst texture\n",
    "#C24. n -2.15158438  worst area\n",
    "#C23. n -2.21834932  worst perimeter\n",
    "#C21. n -2.3582086   worst radius\n",
    "#C7. n -2.48155437   mean concavity\n",
    "#C28. n -3.27399809  worst concave points\n",
    "#C8. n -3.34113606   mean concave points\n",
    "# We can see that there are more coefficients that are more negatively related coefficient to the target than\n",
    "#positively related ones. Since we have normalized the data, we should see the absolute value of the coefficients\n",
    "#the bigger the absolute value, the more impact on the target. Top 3 impact on the target are C8, C28, and C7, all \n",
    "#negatively related. And the top 3 positively related are C10, C20, C16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac060348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question3.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import numpy as np\n",
    "import random\n",
    "from random import seed\n",
    "from random import randrange\n",
    "california_housing = fetch_california_housing(as_frame=True)\n",
    "DF = california_housing.frame\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "635790b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b. Choose the following features from the dataset as your X matrix: MedInc,HouseAge, AveRooms,\n",
    "# AveBedrms, Population, AveOccup, Latitude, Longitude\n",
    "X = DF[['MedInc','HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c8941c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c. Choose the following feature from the dataset as your Y matrix: MedHouseVal\n",
    "Y = DF[['MedHouseVal']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "701026ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d. Apply 0 â€“ 1 normalization on X and Y\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "scaler=MinMaxScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "Y=scaler.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4216839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "\n",
    "def train_test_split(dataset, split=0.7):\n",
    "\ttrain = list()\n",
    "\ttrain_size = split * len(dataset)\n",
    "\tdataset_copy = list(dataset)\n",
    "\twhile len(train) < train_size:\n",
    "\t\tindex = randrange(len(dataset_copy))\n",
    "\t\ttrain.append(dataset_copy.pop(index))\n",
    "\treturn train, dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13e32f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(265)\n",
    "X_train, X_test = train_test_split(X, split=0.7)\n",
    "Y_train, Y_test = train_test_split(Y, split=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab03a755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train,Y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f67dac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "428739c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05683928721425309"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_tts = ((Y - Y_pred)**2).mean()\n",
    "MSE_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd51181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "def k_fold_CV(X, Y, folds=5):\n",
    "    X_split = list()\n",
    "    Y_split = list()\n",
    "    X_copy = list(X)\n",
    "    Y_copy = list(Y)\n",
    "    fold_size= int(len(X) / folds)\n",
    "    for i in range(folds):\n",
    "        fold_X = list()\n",
    "        fold_Y = list()\n",
    "        while len(fold_X) < fold_size:\n",
    "            index = randrange(len(X_copy))\n",
    "            fold_X.append(X_copy.pop(index))\n",
    "            fold_Y.append(Y_copy.pop(index))\n",
    "        X_split += fold_X\n",
    "        Y_split += fold_Y\n",
    "    return X_split, Y_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1da8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(265)\n",
    "folds_X, folds_Y = k_fold_CV(X, Y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4d06984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LinearRegression()\n",
    "def Mean_Square_Error(folds_X, folds_Y, X, Y, folds=5):\n",
    "    MSE = 0\n",
    "    train_X = list(folds_X)\n",
    "    train_Y = list(folds_Y)\n",
    "    model = linear_model.LinearRegression()\n",
    "    for i in range (0,folds):\n",
    "        train_X = train_X[:i] + train_X[i+1:]\n",
    "        train_Y = train_Y[:i] + train_Y[i+1:]\n",
    "        model.fit(train_X, train_Y)\n",
    "        Y_pred=model.predict(X)\n",
    "        MSE += ((Y - Y_pred)**2).mean()\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d07d4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022290007538263358"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_5 = Mean_Square_Error(folds_X, folds_Y, X, Y, 5)\n",
    "MSE_5/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "847a7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "def LOOCV(X, Y, folds=20640):\n",
    "    X_split = list()\n",
    "    Y_split = list()\n",
    "    X_copy = list(X)\n",
    "    Y_copy = list(Y)\n",
    "    fold_size= int(len(X) / folds)\n",
    "    for i in range(folds):\n",
    "        fold_X = list()\n",
    "        fold_Y = list()\n",
    "        while len(fold_X) < fold_size:\n",
    "            index = randrange(len(X_copy))\n",
    "            fold_X.append(X_copy.pop(index))\n",
    "            fold_Y.append(Y_copy.pop(index))\n",
    "        X_split += fold_X\n",
    "        Y_split += fold_Y\n",
    "    return X_split, Y_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc01da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(265)\n",
    "folds_X, folds_Y = LOOCV(X, Y, 20640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2dd04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LinearRegression()\n",
    "def Mean_Square_Error(folds_X, folds_Y, X, Y, folds):\n",
    "    MSE = 0\n",
    "    train_X = list(folds_X)\n",
    "    train_Y = list(folds_Y)\n",
    "    model = linear_model.LinearRegression()\n",
    "    for i in range (0,folds):\n",
    "        train_X = train_X[:i] + train_X[i+1:]\n",
    "        train_Y = train_Y[:i] + train_Y[i+1:]\n",
    "        model.fit(train_X, train_Y)\n",
    "        Y_pred=model.predict(X)\n",
    "        MSE += ((Y - Y_pred)**2).mean()\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07c12a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02233024836307525"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_20640 = Mean_Square_Error(folds_X, folds_Y, X, Y, 20640)\n",
    "MSE_20640/20640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeccc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The k-fold MSE is 0.022290007538263358\n",
    "#The train-test split MSE is 0.05683928721425309\n",
    "#The LOOCV MSE is 0.02233024836307525\n",
    "#We can see that the MSE for k-fold and LOOCV are similar and both smaller than train test split.\n",
    "#This is because they do more training, more data to train in the training process, so more accurate\n",
    "#Also, they calculates the mean of MSE, so the MSE is smaller than train-test- split CV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
